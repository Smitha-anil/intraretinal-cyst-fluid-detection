{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1Cb57anqOrC"
   },
   "source": [
    "# Retinal Cyst detection\n",
    "## First look at unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UzuOIkGvs2uo",
    "outputId": "ef982382-f6f8-4a7f-8fb6-759655fd7e4f"
   },
   "outputs": [],
   "source": [
    "# First make sure you have install these two libraries:\n",
    "!pip install SimpleITK\n",
    "!pip install -U pydicom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60XXGdRZtOzf"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pydicom as dicom\n",
    "from IPython import display\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "matplotlib.rcParams['figure.figsize'] = [8, 6]\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeUxvE19JD_S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1j2f8D3ZtTgK",
    "outputId": "d20903d7-54b9-4aa4-c750-0ee51b1d3d5c"
   },
   "outputs": [],
   "source": [
    "# Only run this code when using Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1er_jQelqd3Z"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xemfKD4E4LLb"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjPX7rJLqKos"
   },
   "outputs": [],
   "source": [
    "# DATA_FOLDER = './cyst_segmentation_ISMI_training_set/'                                  # Local System\n",
    "DATA_FOLDER = 'gdrive/Team Drives/ISMI-FinalProject/cyst_segmentation_ISMI_training_set/' # Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JTYbBLFoukP4",
    "outputId": "4853811b-ddc6-4f83-c155-aecc86843dce"
   },
   "outputs": [],
   "source": [
    "!ls DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYWbI614gytY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "7wpEcR3sxTqK",
    "outputId": "25f3afbb-67be-459c-ba17-8035300798d6"
   },
   "outputs": [],
   "source": [
    "# raw data in ITK format\n",
    "raw_img_filename = os.path.join(DATA_FOLDER,'images/pat001_im001.mhd')\n",
    "out_img_filename = os.path.join(DATA_FOLDER,'annotations/pat001_im001.mhd')\n",
    "\n",
    "# read ITK files using SimpleITK\n",
    "raw_img = sitk.ReadImage(raw_img_filename)\n",
    "out_img = sitk.ReadImage(out_img_filename)\n",
    "\n",
    "# print image information\n",
    "print('image size: {}'.format(raw_img.GetSize()))\n",
    "print('image origin: {}'.format(raw_img.GetOrigin()))\n",
    "print('image spacing: {}'.format(raw_img.GetSpacing()))\n",
    "print('image width: {}'.format(raw_img.GetWidth()))\n",
    "print('image height: {}'.format(raw_img.GetHeight()))\n",
    "print('image depth: {}'.format(raw_img.GetDepth()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6jkvMZPxbuM"
   },
   "outputs": [],
   "source": [
    "# convert the ITK image into numpy format\n",
    "out_np = sitk.GetArrayFromImage(out_img)\n",
    "raw_np = sitk.GetArrayFromImage(raw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0E25Rw2FxyIv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8RfrOKEx2DF"
   },
   "outputs": [],
   "source": [
    "def get_file_list(path, ext=''):\n",
    "    return sorted([os.path.join(path, f) for f in os.listdir(path) if f.endswith(ext)])\n",
    "\n",
    "def load_img(path):\n",
    "    return sitk.GetArrayFromImage(sitk.ReadImage(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQA7I3ZNE-fV"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XxffaKqzIuo"
   },
   "outputs": [],
   "source": [
    "# get path names list of raw data in ITK format\n",
    "x_img_files = get_file_list(Path(DATA_FOLDER,'images/'), 'mhd')\n",
    "y_img_files = get_file_list(Path(DATA_FOLDER,'annotations/'), 'mhd')\n",
    "\n",
    "\n",
    "# read ITK files using SimpleITK and conver then into a list of numpy arrays\n",
    "#X = [load_img(f) for f in x_img_files]\n",
    "#Y = [load_img(f) for f in y_img_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_UD1YrI0Qmt"
   },
   "source": [
    "# Code from assignment 7 (Unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j5kZWwKA0G_r",
    "outputId": "bc8527c1-785e-446b-86b3-b570923ea4e0"
   },
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import requests\n",
    "from tqdm import trange\n",
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import matplotlib\n",
    "from random import randint\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from skimage.transform import rescale, resize\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input,Dense, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, Cropping2D, Reshape, BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import regularizers\n",
    "import keras.callbacks\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NiJ3nM_JKXz"
   },
   "outputs": [],
   "source": [
    "# adding growth parameter for GPU memory allocation\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "#!pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fjUm9U76An2"
   },
   "outputs": [],
   "source": [
    "class Image:\n",
    "  \n",
    "  def __init__(self, img, label=None, name=None, width = None, origin = None, spacing =None):\n",
    "    '''\n",
    "    Inputs:\n",
    "    img: image as a numpy array\n",
    "    label: labels of the image as np image\n",
    "    name: the filename of the image\n",
    "    '''\n",
    "    self.img = img\n",
    "    self.label = label\n",
    "    self.name = name\n",
    "    self.width = width\n",
    "    self.origin = origin\n",
    "    self.spacing = spacing\n",
    "    \n",
    "  def get_img(self):\n",
    "    return self.img\n",
    "  \n",
    "  def get_label(self):\n",
    "    return self.label\n",
    "  \n",
    "  def show_img(self):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    print(self.img.shape)\n",
    "    plt.imshow(self.img.reshape(256,256)); plt.title('RGB image')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(self.label.reshape(256,256),cmap='Greys'); plt.title('Label')\n",
    "    plt.show()\n",
    "  def get_name():\n",
    "    return self.name\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScFUuL7PeXPs"
   },
   "outputs": [],
   "source": [
    "def pad_n_crop_(img, cropx, cropy):\n",
    "  #print(img.shape)\n",
    "  #img = np.pad(img, ((0,0),(0,0),(0,0)), mode='edge')\n",
    "  #maybe do not pad? \n",
    "  #print(img.shape)\n",
    "  _, y,x = img.shape\n",
    "  startx = x//2-(cropx//2)\n",
    "  starty = y//2-(cropy//2)    \n",
    "  return img[:, starty:starty+cropy,startx:startx+cropx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBJeuTkDd2BL"
   },
   "outputs": [],
   "source": [
    "\n",
    "validation_percent = 0.2 \n",
    "n_validation_files = int(validation_percent * len(x_img_files))\n",
    "#NEED A CLEAN CUT HERE BETWEEN VOLUMES\n",
    "# coefficient to define validation dataset (value between 0 and 1)\n",
    "# Do this with a more random split\n",
    "\n",
    "train_x_files = x_img_files[n_validation_files:]\n",
    "train_y_files = y_img_files[n_validation_files:]\n",
    "\n",
    "validation_x_files = x_img_files[:n_validation_files]\n",
    "validation_y_files = y_img_files[:n_validation_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtCqCxgbUqL8"
   },
   "outputs": [],
   "source": [
    "validation_data = []\n",
    "train_data =[]\n",
    "\n",
    "for x_file, y_file in zip(train_x_files, train_y_files):\n",
    "  img = load_img(x_file).astype('float32')\n",
    "  img = pad_n_crop_(img, 256, 256).reshape(img.shape[0],256,256,1)/255.\n",
    "  label = load_img(y_file)\n",
    "  label = pad_n_crop_(label, 256, 256)\n",
    "  name = x_file.split('/')[-1]\n",
    "  for i in range(img.shape[0]):\n",
    "    #print(img.shape)\n",
    "    image = Image(img[i,:,:], label[i,:,:], name)\n",
    "    #print(image.get_img().shape)\n",
    "    train_data.append(image)\n",
    "    \n",
    "for x_file, y_file in zip(validation_x_files, validation_y_files):\n",
    "  img = load_img(x_file).astype('float32')\n",
    "  img = pad_n_crop_(img, 256, 256).reshape(img.shape[0],256,256,1)/255.\n",
    "  label = load_img(y_file)\n",
    "  label = pad_n_crop_(label, 256, 256)\n",
    "  name = x_file.split('/')[-1]\n",
    "  for i in range(img.shape[0]):\n",
    "    #print(img.shape)\n",
    "    image = Image(img[i,:,:], label[i,:,:], name)\n",
    "    #print(image.get_img().shape)\n",
    "    validation_data.append(image)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sdZenYFiSTP"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAUIkXZiEW5T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjBmi8eB03Jg"
   },
   "outputs": [],
   "source": [
    "class BatchCreator:\n",
    "    \n",
    "    def __init__(self, dataset, target_size):\n",
    "        #self.patch_extractor = patch_extractor\n",
    "        self.target_size = target_size # size of the output, can be useful when valid convolutions are used\n",
    "        \n",
    "        self.imgs = [image.img for image in dataset]\n",
    "        self.lbls = [image.label for image in dataset]\n",
    "                \n",
    "        self.n = len(self.imgs)\n",
    "        #self.patch_size = self.patch_extractor.patch_size\n",
    "    \n",
    "    def create_image_batch(self, batch_size):\n",
    "        '''\n",
    "        returns a single augmented image (x) with corresponding labels (y) in one-hot structure\n",
    "        '''\n",
    "        x_data = np.zeros((batch_size, 256,256, 1))\n",
    "        y_data = np.zeros((batch_size, 256,256, 2)) # one-hot encoding with 2 classes\n",
    "        sw = np.zeros((batch_size,1,1,1))\n",
    "        for i in range(0, batch_size):\n",
    "        \n",
    "            random_index = np.random.choice(len(self.imgs)) # pick random image\n",
    "            img, lbl = self.imgs[random_index], self.lbls[random_index] # get image and segmentation map\n",
    "            \n",
    "           # clear_output()\n",
    "            #patch_img, patch_lbl = self.patch_extractor.get_patch(img, lbl) # when image size is equal to patch size, this line is useless...\n",
    "          #  img, lbl = \n",
    "            # crop labels based on target_size\n",
    "            #h, w, _ = patch_lbl.shape\n",
    "            #ph = (self.patch_extractor.patch_size[0] - self.target_size[0]) // 2\n",
    "            #pw = (self.patch_extractor.patch_size[1] - self.target_size[1]) // 2\n",
    "            #patch_img = patch_img.reshape(tuple(list(patch_img.shape) + [1]))\n",
    "            r = random.random()\n",
    "            unique, counts = np.unique(img, return_counts=True)\n",
    "            w_background = 0.5 / (counts[0]/(np.sum(counts)))\n",
    "            w_foreground = 0.5 / (counts[1]/(np.sum(counts)))\n",
    "            x_data[i, :, :, :] = img\n",
    "            y_data[i, :, :, 0] = 1 - lbl\n",
    "            y_data[i, :, :, 1] = lbl\n",
    "            sw[i,0,:,:] =  w_foreground\n",
    "            sw[i,:,0,:] = w_background\n",
    "            #print(len(y_data.shape))\n",
    "            #maybe just return one y_data? \n",
    "        return (x_data.astype(np.float32), y_data.astype(np.float32), sw.flatten())\n",
    "    \n",
    "    def get_image_generator(self, batch_size):\n",
    "        '''returns a generator that will yield image-batches infinitely'''\n",
    "        while True:\n",
    "            yield self.create_image_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOhriKTF1hER"
   },
   "outputs": [],
   "source": [
    "def crop(masks, lost_border):\n",
    "    ph = lost_border[0] // 2\n",
    "    pw = lost_border[1] // 2\n",
    "    h, w = masks[0].shape    \n",
    "    return np.array(masks)[:, ph:h-ph, pw:w-pw]   \n",
    "\n",
    "def calculate_dice(x, y):\n",
    "    '''returns the dice similarity score, between two boolean arrays'''\n",
    "    return 2 * np.count_nonzero(x & y) / (np.count_nonzero(x) + np.count_nonzero(y))\n",
    "    \n",
    "class Logger(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, validation_data, lost_border, data_dir, model_name):\n",
    "        self.val_imgs = np.array([image.img for image in validation_data]) \n",
    "        self.val_lbls = crop([image.label for image in validation_data], lost_border)\n",
    "        self.model_filename = os.path.join(data_dir, model_name + '.h5')\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.dices = []\n",
    "        self.val_dices = []\n",
    "        self.best_dice = 0\n",
    "        self.best_model = None\n",
    "        \n",
    "        self.predictions = None\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "    \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        dice = self.validate()\n",
    "        self.dices.append([len(self.losses), dice])\n",
    "        if dice > self.best_dice:\n",
    "            self.best_dice = dice\n",
    "            self.model.save(self.model_filename) # save best model to disk\n",
    "            print('best model saved as {}'.format(self.model_filename))\n",
    "        self.plot()   \n",
    "        print(self.best_dice)\n",
    "    \n",
    "    def validate(self):\n",
    "        self.predictions = self.model.predict(self.val_imgs, batch_size=1)\n",
    "        predicted_lbls = np.argmax(self.model.predict(self.val_imgs, batch_size=1), axis=3)\n",
    "        x = self.val_lbls>0\n",
    "        y = predicted_lbls>0\n",
    "        return calculate_dice(x, y)\n",
    "    \n",
    "    def plot(self):\n",
    "        clear_output()\n",
    "        N = len(self.losses)\n",
    "        plt.figure(figsize=(50, 10))\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.plot(range(0, N), self.losses); \n",
    "        plt.plot(range(0, N), self.val_losses); \n",
    "        plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.plot(*np.array(self.dices).T); plt.title('dice')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1zOaH8DBYIG"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJPR8wsBEojw"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDIQXHbFCPfh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMBNNICY3DFk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "dAfyiQJXSg9g",
    "outputId": "e1b65c73-964b-4241-f202-07addc252294"
   },
   "outputs": [],
   "source": [
    "# define parameters for patch generator and batch creator\n",
    "#patch_size = (32, 32) # input size\n",
    "target_size = (256, 256) # output size, might be the same as input size, but might be smaller, if valid convolutions are used\n",
    "batch_size =  6 # number of patches in a mini-batch\n",
    "\n",
    "# intialize patch generator and batch creator\n",
    "#patch_generator = PatchExtractor(patch_size)\n",
    "batch_generator = BatchCreator(train_data, target_size=target_size)\n",
    "validation_generator = BatchCreator(validation_data, target_size=target_size)\n",
    "# get one minibatch\n",
    "x_data, y_data, sw = validation_generator.create_image_batch(batch_size)\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "print(y_data[0, :, :, 0].squeeze().shape)\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(x_data[i].reshape(256,256)); plt.title('RGB image')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(y_data[i, :, :, 0].squeeze()); plt.title('Label map class 0')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(y_data[i, :, :, 1].squeeze()); plt.title('Label map class 1')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5L1Ry3P8nDNc"
   },
   "outputs": [],
   "source": [
    "# Create a function that builds a U-Net block, containing conv->(batchnorm->)conv->(batchnorm),\n",
    "# where batchnorm is optional and can be selected via input parameter.\n",
    "# The function returns the output of a convolutional (or batchnorm) layer \"cl\"\n",
    "def unet_block(inputs, n_filters, batchnorm=False, name= None):\n",
    "    \n",
    "    # >> YOUR CODE HERE <<\n",
    "    cl = Conv2D(n_filters,3, activation = 'relu', padding = 'same',kernel_initializer ='he_normal', name = name+\"1\" )(inputs)\n",
    "    cl = BatchNormalization()(cl) if batchnorm else cl\n",
    "    cl = Conv2D(n_filters,3,activation = 'relu', padding = 'same',kernel_initializer='he_normal',name = name+\"2\")(cl)\n",
    "    cl = BatchNormalization()(cl) if batchnorm else cl\n",
    "    \n",
    "    return cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GL2k9IWc49L"
   },
   "outputs": [],
   "source": [
    "def build_unet_2(initial_filters=32, n_classes=2, batchnorm=False, printmodel=False):\n",
    "\n",
    "    # build U-Net again using unet_block function\n",
    "    inputs = Input(shape=(256, 256, 1))\n",
    "\n",
    "    # CONTRACTION PART\n",
    "\n",
    "    # First conv pool\n",
    "    c1 = unet_block(inputs, initial_filters, batchnorm,name ='first')\n",
    "    p1 = MaxPooling2D()(c1)\n",
    "\n",
    "    # Second conv pool\n",
    "    c2 = unet_block(p1, 2*initial_filters, batchnorm,name='second')\n",
    "    p2 = MaxPooling2D()(c2)\n",
    "\n",
    "    # Third conv pool\n",
    "    c3 = unet_block(p2, 4*initial_filters, batchnorm,name='third')\n",
    "    p3 = MaxPooling2D()(c3)\n",
    "\n",
    "    # Fourth conv\n",
    "    c4 = unet_block(p3, 8*initial_filters, batchnorm, name='fourth')\n",
    "\n",
    "    # EXPANSION PART\n",
    "\n",
    "    # First up-conv\n",
    "    u2 = UpSampling2D()(c4)\n",
    "    m2 = concatenate([c3, u2])\n",
    "    cm2 = unet_block(m2, 4*initial_filters, batchnorm, name ='fifth')\n",
    "\n",
    "    # Second up-conv\n",
    "    u3 = UpSampling2D()(cm2)\n",
    "    m3 = concatenate([c2, u3])\n",
    "    cm3 = unet_block(m3, 2*initial_filters, batchnorm, name ='sixth')\n",
    "\n",
    "    # Third up-conv\n",
    "    u4 = UpSampling2D()(cm3)\n",
    "    m4 = concatenate([c1, u4])\n",
    "    cm4 = unet_block(m4, initial_filters, batchnorm, name = 'seventh')\n",
    "\n",
    "    # Output\n",
    "    predictions = Conv2D(n_classes, 1, activation='softmax', name = 'last')(cm4)\n",
    "\n",
    "    model = Model(inputs, predictions)\n",
    "    \n",
    "    if printmodel:\n",
    "        print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "0Sd_Zsgxkn23",
    "outputId": "80151abf-a118-4443-be02-7e0d0a6bbb8f"
   },
   "outputs": [],
   "source": [
    "unet_1 = build_unet_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ny9mjI-p1PMj"
   },
   "outputs": [],
   "source": [
    "def apply_model(model, dataset, experiment_name='basic_unet', make_submission_file=False):\n",
    "    \"\"\"Apply a given model to the test set, optionally makes a submission file in ZIP format.\"\"\"\n",
    "    \n",
    "    output_dir = os.path.join('.', experiment_name)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    imgs = [image.img for image in dataset]\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        fig = plt.figure(figsize=(10,20))\n",
    "        input_img = np.expand_dims(imgs[i], axis=0)\n",
    "        output = model.predict(input_img, batch_size=1)[0, :, :]\n",
    "        plt.subplot(1, 2, 1); plt.imshow(imgs[i].reshape(256,256))\n",
    "        plt.subplot(1, 2, 2); plt.imshow(np.argmax(output, axis=2))\n",
    "        if make_submission_file:\n",
    "            prediction = Image.fromarray(np.argmax(output, axis=2).astype(np.uint8))\n",
    "            prediction.save(os.path.join(output_dir, '{}.png'.format(i)))\n",
    "        plt.show()\n",
    "        \n",
    "    if make_submission_file:\n",
    "        shutil.make_archive('results', 'zip', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhBSUzyjkt3M"
   },
   "outputs": [],
   "source": [
    "# apply the model to the validation set\n",
    "data_dir = '.'\n",
    "#apply_model(unet_1, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57psGYrVYhy9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18jcVE77sUEx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBVOCK9n-UkY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUhJHHLlu8Vz"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ao82zyNd6FNg"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=10, min_delta=0.001, min_lr=0.00001) #should be val_loss later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIJcjZjWu2wb"
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=20, \n",
    "                                  verbose=0, mode='auto', baseline=None, restore_best_weights=False) # shoud be val_loss later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRR_z_th7jSh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTy1NrCX7EQd"
   },
   "outputs": [],
   "source": [
    "val_imgs = []\n",
    "val_lbls = []\n",
    "for v in validation_data:\n",
    "  val_imgs.append(v.img.reshape(256,256,1))\n",
    "  label = np.zeros((256,256, 2))\n",
    "  label[:,:,0] = v.label\n",
    "  label[:,:,1] = 1- v.label\n",
    "  val_lbls.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CafygDzHVF_7"
   },
   "outputs": [],
   "source": [
    "# function to train a model\n",
    "def train_model(model, training_params):\n",
    "    \n",
    "    patch_size = training_params['patch_size']\n",
    "    target_size = training_params['target_size']\n",
    "    batch_size = training_params['batch_size']\n",
    "    loss = training_params['loss']\n",
    "    metrics = training_params['metrics']\n",
    "    logger = training_params['logger']\n",
    "    epochs = training_params['epochs']\n",
    "    steps_per_epoch = training_params['steps_per_epoch']\n",
    "    optimizer = training_params['optimizer']\n",
    "    training_dataset = training_params['training_dataset']\n",
    "    validation_dataset = training_params['validation_dataset']\n",
    "    # batch generator \n",
    "    #patch_generator = PatchExtractor(patch_size)\n",
    "    batch_generator = BatchCreator(training_dataset, target_size=target_size)\n",
    "    image_generator = batch_generator.get_image_generator(batch_size)\n",
    "    validation_generator = BatchCreator(validation_dataset, target_size=target_size)\n",
    "    val_generator = validation_generator.get_image_generator(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    # train the model\n",
    "    model.fit_generator(generator=image_generator, \n",
    "                        steps_per_epoch=steps_per_epoch, \n",
    "                        #class_weight = [0000.5,500000],\n",
    "                        #class_weight = class_weight,\n",
    "                        epochs=epochs,\n",
    "                        validation_data = val_generator,\n",
    "                        validation_steps = len(validation_data)/batch_size,\n",
    "                        callbacks=[logger,reduce_lr,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "colab_type": "code",
    "id": "IkjlKKPUkwZR",
    "outputId": "f55d8b7f-a8f8-45f0-c0f9-d9640b10ddc8"
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "unet_1 = build_unet_2()\n",
    "model_name = 'unet_1'\n",
    "\n",
    "training_params = {}\n",
    "training_params['learning_rate'] = 0.001\n",
    "training_params['patch_size'] = (256, 256) # input size\n",
    "training_params['target_size'] = (256, 256) # output size, might be the same as input size, but might be smaller, if valid convolutions are used\n",
    "training_params['batch_size'] = 6 # number of patches in a mini-batch\n",
    "training_params['steps_per_epoch'] = 100 # number of iterations per epoch\n",
    "training_params['epochs'] = 1000 # number of epochs\n",
    "\n",
    "training_params['optimizer'] = SGD(lr=training_params['learning_rate'], momentum=0.99, nesterov=True)\n",
    "training_params['loss'] = ['categorical_crossentropy']\n",
    "#training_params['loss'] = weightedLoss(['categorical_crossentropy'],[5000,0.0001])\n",
    "training_params['metrics'] = ['acc']\n",
    "training_params['training_dataset'] = train_data\n",
    "training_params['validation_dataset'] = validation_data\n",
    "\n",
    "# initialize a logger, to keep track of information during training\n",
    "lost_border = ((training_params['patch_size'][0]-training_params['target_size'][0])//2, (training_params['patch_size'][1]-training_params['target_size'][1])//2)\n",
    "training_params['logger'] = Logger(validation_data, lost_border, data_dir, model_name)\n",
    "\n",
    "# train model\n",
    "train_model(unet_1, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0SXqK0pXpZjO",
    "outputId": "f0b04b6c-21bd-4d76-92bd-d0a7fd347070"
   },
   "outputs": [],
   "source": [
    "\n",
    "wt_path2 = os.path.join(os.getcwd(), 'unet_1.h5')\n",
    "unet_1.load_weights(wt_path2)\n",
    "print(\"Weights loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QlfOFEw46N1e"
   },
   "outputs": [],
   "source": [
    "apply_model(unet_1, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iu3A1Fay5iKf"
   },
   "outputs": [],
   "source": [
    "TEST_FOLDER = 'gdrive/Team Drives/ISMI-FinalProject/cyst_segmentation_ISMI_test_set/cyst_segmentation_ISMI_test_set/' # Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c3wXVIno3mjF",
    "outputId": "17bca633-f8e1-463e-bbf3-bc18f37d47d0"
   },
   "outputs": [],
   "source": [
    "!ls 'gdrive/Team Drives/ISMI-FinalProject/cyst_segmentation_ISMI_test_set/cyst_segmentation_ISMI_test_set/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KA5bKaDE7lKH"
   },
   "outputs": [],
   "source": [
    "def pad_prediction(prediction, input_size, pad_with=-1.0):\n",
    "    \"\"\"Only for visualization purpose, it introduces artificial -1.\"\"\"\n",
    "    pad_pred = pad_with * np.ones(input_size).astype(float)\n",
    "    pred_size = prediction.shape\n",
    "    D = ((input_size[0]-pred_size[0])//2, (input_size[1]-pred_size[1])//2)\n",
    "    pad_pred[D[0]:D[0]+pred_size[0], D[1]:D[1]+pred_size[1]] = prediction\n",
    "    return pad_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AquUmIpvnMd7"
   },
   "outputs": [],
   "source": [
    "x_test_files = get_file_list(os.path.join(TEST_FOLDER,'images/'), 'mhd')\n",
    "test_imgs = []\n",
    "origins = []\n",
    "spacings =[]\n",
    "for t in x_test_files:\n",
    "  img = load_img(t).astype('float32')\n",
    "  width = img.shape[2]\n",
    "  raw = sitk.ReadImage(t)\n",
    "  origins.append(raw.GetOrigin())\n",
    "  spacings.append(raw.GetSpacing())\n",
    "  img = pad_n_crop_(img, 256, 256).reshape(img.shape[0],256,256,1)/255.\n",
    "  temp = t.split('/')[-1]\n",
    "  name = temp.split('.')[0]\n",
    "  for i in range(img.shape[0]):\n",
    "    #print(img.shape)\n",
    "    image = Image(img[i,:,:], name = name, width=width)\n",
    "    #print(image.get_img().shape)\n",
    "    test_imgs.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxa-yL3A3GDF"
   },
   "outputs": [],
   "source": [
    "p = []\n",
    "for i in test_imgs:\n",
    "  x = unet_1.predict(i.img.reshape(1,256,256,1))\n",
    " ## xx = np.argmax(x,axis=3)\n",
    "  xx = Image(pad_prediction(np.argmax(x,axis=3).reshape(256,256),(496,i.width), pad_with=0.0),name=i.name, width = i.width)\n",
    "  p.append(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "WhQVUq5xO_lA",
    "outputId": "e114abbe-b5d3-4128-951f-714fe7145ef9"
   },
   "outputs": [],
   "source": [
    "# read ITK files using SimpleITK\n",
    "raw_img = sitk.ReadImage(raw_img_filename)\n",
    "out_img = sitk.ReadImage(out_img_filename)\n",
    "\n",
    "# print image information\n",
    "print('image size: {}'.format(raw_img.GetSize()))\n",
    "print('image origin: {}'.format(raw_img.GetOrigin()))\n",
    "print('image spacing: {}'.format(raw_img.GetSpacing()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TQ6ca1GNgXj"
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "for n in p:\n",
    "  names.append(n.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "x3d0wAlNRAJ2",
    "outputId": "e2720d2c-b23b-47dc-ffa4-5bca490d6103"
   },
   "outputs": [],
   "source": [
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EofSYxEu6LJ4"
   },
   "outputs": [],
   "source": [
    "unique,counts = np.unique(names,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG7-9LPw-yJt"
   },
   "outputs": [],
   "source": [
    "volumes = []\n",
    "for u in unique: \n",
    "   volume = []\n",
    "   for pic in p:\n",
    "     if pic.name == u:\n",
    "        volume.append(pic.img)\n",
    "   volumes.append(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmb6Ukc3NuQd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdbKZOoBT-qN"
   },
   "outputs": [],
   "source": [
    "img = sitk.GetImageFromArray(volumes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWsYa8VgDAWs"
   },
   "outputs": [],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8msvQMyS6nL8"
   },
   "outputs": [],
   "source": [
    "def save_itk(image,spacing, origin, filename):\n",
    "    itkimage = sitk.GetImageFromArray(image, isVector=False)\n",
    "    itkimage.SetSpacing(spacing)\n",
    "    itkimage.SetOrigin(origin)\n",
    "    sitk.WriteImage(itkimage, filename) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzbBMy-TPNAM"
   },
   "outputs": [],
   "source": [
    "!mkdir \"new_new_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x127FRxOTXLO"
   },
   "outputs": [],
   "source": [
    "for v in range(len(volumes)):\n",
    "  output_file_name = os.path.join('new_new_new', str.replace('test_x.mhd','x',str(v)))\n",
    "  save_itk(volumes[v],spacings[v],origins[v],output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AuMkCF4b9qbE"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLDfeCb69I1f"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_file = zipfile.ZipFile('new_new_new.zip', 'w')\n",
    "zip_file.write('new_new_new', compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eL5fkGtzIL3M"
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'new_tests/' # Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNnR_xkZHhm8"
   },
   "outputs": [],
   "source": [
    "# get path names list of raw data in ITK format\n",
    "xxx = get_file_list(Path(DATA_FOLDER,'.'), 'mhd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "5cDaFd0ZIUHp",
    "outputId": "4ae96b73-a1dc-4feb-ee10-985b8803fdd1"
   },
   "outputs": [],
   "source": [
    "sexy = []\n",
    "for x_file in xxx:\n",
    "  img = load_img(x_file).astype('float32')\n",
    "  print(img.shape)\n",
    "  img = pad_n_crop_(img, 256, 256).reshape(img.shape[0],256,256,1)/255.\n",
    "  for i in range(img.shape[0]):\n",
    "    #print(img.shape)\n",
    "    image = Image(img[i,:,:])\n",
    "    #print(image.get_img().shape)\n",
    "    sexy.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-cyGYwcIsmB"
   },
   "outputs": [],
   "source": [
    "for i in range(len(sexy)):\n",
    "    fig = plt.figure(figsize=(10,20))\n",
    "    plt.subplot(1, 2, 1); plt.imshow(sexy[i].img.reshape(256,256))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYau3Fa5Itk4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "first_try_unet.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
